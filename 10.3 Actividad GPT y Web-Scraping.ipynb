{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install selenium bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import time \n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.tripadvisor.com/Hotel_Review-g150782-d155753-Reviews-Krystal_Monterrey-Monterrey_Northern_Mexico.html#REVIEWS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the file to save the review\n",
    "csvFile = open(\"hotel_reviews2.csv\", 'a', encoding=\"utf-8\")\n",
    "csvWriter = csv.writer(csvFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_to_scrape=120\n",
    "\n",
    "driver = webdriver.Firefox()\n",
    "driver.get(url)\n",
    "\n",
    "for i in range(0, pages_to_scrape):\n",
    "    print(i)\n",
    "   \n",
    "    time.sleep(2)\n",
    "\n",
    "    driver.find_element(\"xpath\",\"/html/body/div[2]/div[2]/div[2]/div[10]/div/div[1]/div[1]/div/div/div[3]/div[1]/div[1]/div[4]/ul/li[2]/label\").click()\n",
    "\n",
    "    # Click en el enlace \"expandir opinión\" para revelar toda la opinión.\n",
    "    driver.find_element(\"xpath\",\".//div[contains(@data-test-target, 'expand-review')]\").click()\n",
    "\n",
    "    # Contenedor que contendrá todas las opiniones de la página.\n",
    "    container = driver.find_elements(\"xpath\",\"//div[@data-reviewid]\")\n",
    "   \n",
    "   # Opiniones dentro del contenedor\n",
    "    for j in range(len(container)):\n",
    "        \n",
    "        # Obtener calificacion\n",
    "        rating = container[j].find_element(\"xpath\",\".//span[contains(@class, 'ui_bubble_rating bubble_')]\").get_attribute(\"class\").split(\"_\")[3]\n",
    "        # Obtener titulo\n",
    "        title = container[j].find_element(\"xpath\",\".//div[contains(@data-test-target, 'review-title')]\").text\n",
    "        # Obtener opinion\n",
    "        review = container[j].find_element(\"xpath\",\".//span[@class='QewHA H4 _a']/span\").text.replace(\"\\n\", \"  \")\n",
    "        # Guarda los datos en el csv y luego continúa procesando la siguiente opinión\n",
    "        csvWriter.writerow([rating, title, review])\n",
    "\n",
    "    # Cuando todas las opiniones en el contenedor hayan sido procesadas, cambia la página y repite\n",
    "    driver.find_element(\"xpath\",'.//a[@class=\"ui_button nav next primary \"]').click()\n",
    "\n",
    "# Cuando todas las páginas hayan sido procesadas, cierra el driver\n",
    "driver.quit()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Problema binario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>Excelente Hotel en Centro de Monterrey</td>\n",
       "      <td>Si buscas un hotel en el Centro de Monterrey H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Tus eventos en el Krystal</td>\n",
       "      <td>Muy buen servicio y atención del todo el perso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>Excelente opción para eventos y grupos.</td>\n",
       "      <td>Excelente servicio y atención personal. Muy bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>Geting ready</td>\n",
       "      <td>El mes pasado mi prima tuvo su getting y me en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>Realizamos un evento y nuestros clientes se fu...</td>\n",
       "      <td>Excelente servicio y atención al cliente.Sobre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                              title  \\\n",
       "0      50             Excelente Hotel en Centro de Monterrey   \n",
       "1      50                          Tus eventos en el Krystal   \n",
       "2      50            Excelente opción para eventos y grupos.   \n",
       "3      50                                       Geting ready   \n",
       "4      50  Realizamos un evento y nuestros clientes se fu...   \n",
       "\n",
       "                                              review  \n",
       "0  Si buscas un hotel en el Centro de Monterrey H...  \n",
       "1  Muy buen servicio y atención del todo el perso...  \n",
       "2  Excelente servicio y atención personal. Muy bu...  \n",
       "3  El mes pasado mi prima tuvo su getting y me en...  \n",
       "4  Excelente servicio y atención al cliente.Sobre...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"hotel_reviews2.csv\", names=['rating', 'title', 'review'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "50    571\n",
       "40    303\n",
       "30    171\n",
       "10     60\n",
       "20     54\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "binary_rating\n",
       "1    874\n",
       "0    285\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['binary_rating'] = df['rating'].apply(lambda x: 1 if x >= 40 else 0)\n",
    "df['binary_rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative comments percentage:  0.2459016393442623\n",
      "Positive comments percentage:  0.7540983606557377\n"
     ]
    }
   ],
   "source": [
    "neg_comments_per = df['binary_rating'].value_counts()[0] / df['binary_rating'].value_counts().sum()\n",
    "pos_comments_per = df['binary_rating'].value_counts()[1] / df['binary_rating'].value_counts().sum()\n",
    "print(\"Negative comments percentage: \", neg_comments_per)\n",
    "print(\"Positive comments percentage: \", pos_comments_per)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "En los datos obtenidos solo había calificaciones con los siguientes valores:\n",
    "\n",
    "| Rating | Count |\n",
    "|--------|-------|\n",
    "| 50     | 571   |\n",
    "| 40     | 303   |\n",
    "| 30     | 171   |\n",
    "| 10     | 60    |\n",
    "| 20     | 54    |\n",
    "\n",
    "Para volverlo un problema de clasificación de sentimientos binarios, se optó por considerar los comentarios con calificación mayor o igual a 40 como positivos.\n",
    "\n",
    "Tras la conversión, el ~24.59% de los comentarios obtenidos son negativos, mientras que el ~75.40% son positivos.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modelo Transformer para generación de comentarios \"sintéticos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "344940c0278b48739611367c0ab10041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n",
      "The model 'RWForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n",
      "c:\\Users\\m1000\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\transformers\\generation\\utils.py:1259: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: Girafatron is obsessed with giraffes, the most glorious animal on the face of this Earth. Giraftron believes all other animals are irrelevant when compared to the glorious majesty of the giraffe.\n",
      "Daniel: Hello, Girafatron!\n",
      "Girafatron: Hello, Daniel.\n",
      "Daniel: I'm sorry to interrupt you, but I'm having a problem with my giraffe.\n",
      "Girafatron: You have a problem with a giraffe? You have a problem with a giraffe?\n",
      "*Girafatron gets up and looks for his gun*\n",
      "Daniel: *looks nervous*\n",
      "Girafatron: Where is it? Where is it?!\n",
      "Daniel: It's in my house, in the attic.\n",
      "Daniel: Oh, I see you have it.\n",
      "Girafatron: I got you, you stupid giraffe! *pulls trigger on the gun and blows a hole in the wall of Daniel's house, killing him.*\n",
      "Daniel: *dead* (I'm sorry, I was busy.)\n",
      "Daniel: *dead* (I'm busy.)\n",
      "Daniel: *dead*\n",
      "Girafatron: I got you, you stupid giraffe! *pulls trigger on the gun and blows a hole in the wall of Daniel's house, killing him.*\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "model = \"tiiuae/falcon-7b\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=1,\n",
    "    max_length=400,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "sequences = pipeline(\n",
    "   \"Girafatron is obsessed with giraffes, the most glorious animal on the face of this Earth. Giraftron believes all other animals are irrelevant when compared to the glorious majesty of the giraffe.\\nDaniel: Hello, Girafatron!\\nGirafatron:\",\n",
    "    max_length=2048,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, HuggingFaceHub, LLMChain, HuggingFacePipeline\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFacePipeline(pipeline = pipeline, model_kwargs={\n",
    "    'temperature':0.45, \n",
    "    'do_sample': True, 'num_return_sequences': 1, 'eos_token_id': tokenizer.eos_token_id\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\m1000\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\langchain\\llms\\openai.py:748: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(model_name=\"gpt-3.5-turbo\", openai_api_key=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No recomiendo este hotel en absoluto. La habitación estaba sucia y maloliente, probablemente no habían limpiado a fondo en semanas. El baño estaba lleno de moho y el inodoro no funcionaba correctamente. Incluso encontré cucarachas en la habitación. El personal fue grosero y poco servicial. No esperes una experiencia agradable si decides alojarte aquí. Hay opciones mucho mejores en la zona.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Comentario negativo 1: Recién remodelado, El hotel acaba de ser remodelado pero se nota una pésima gestión. Las almohadas como estaban hace un año todavía no han sido cambiadas, son viejas bolsas de plumón apestosas aplastadas e incómodas. Hace un año me hospedé ahi y tuve el mismo problema increible no deberian comprar almohadas nuevas para todo el hotel ademas no tienen frazadas en las camas y el clima extremo de monterrey me hizo congelar por 3 noches el aire acondicionado solo enfria pero no tienen calefacción. El personal está desorganizado y sin autoridad para poner orden. El restaurante es viejo y necesita remodelación. \\n\n",
    "Comentario negativo 2: {review}\\n\n",
    "Comentario negativo 3:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"review\"])\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "random_review = df[df['binary_rating'] == 0]['review'].sample(1).values[0]\n",
    "result = llm_chain.run(random_review)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_reviews = []\n",
    "\n",
    "# Use tqdm in the for loop to display a progress bar\n",
    "for i in tqdm(range(0,600)):\n",
    "    random_review = df[df['binary_rating'] == 0]['review'].sample(1).values[0]\n",
    "    result = llm_chain.run(random_review)\n",
    "    print(result)\n",
    "    new_reviews.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(new_reviews, columns=[\"review\"])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "new_df.to_csv(\"synthetic_reviews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La experiencia en este hotel fue decepcionante...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Este hotel es un completo desastre. La habitac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pésimo servicio en el hotel, la gente de recep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>La experiencia en el hotel fue terrible. Desde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mi experiencia en este hotel fue bastante dece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>El servicio al cliente fue muy pobre y decepci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>Mi experiencia en el Fiesta Americana fue muy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>Mi experiencia en este hotel fue completamente...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>La peor experiencia hotelera de mi vida. El pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>Horrible experiencia en este hotel. La habitac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review\n",
       "0    La experiencia en este hotel fue decepcionante...\n",
       "1    Este hotel es un completo desastre. La habitac...\n",
       "2    Pésimo servicio en el hotel, la gente de recep...\n",
       "3    La experiencia en el hotel fue terrible. Desde...\n",
       "4    Mi experiencia en este hotel fue bastante dece...\n",
       "..                                                 ...\n",
       "595  El servicio al cliente fue muy pobre y decepci...\n",
       "596  Mi experiencia en el Fiesta Americana fue muy ...\n",
       "597  Mi experiencia en este hotel fue completamente...\n",
       "598  La peor experiencia hotelera de mi vida. El pe...\n",
       "599  Horrible experiencia en este hotel. La habitac...\n",
       "\n",
       "[600 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.read_csv(\"synthetic_reviews.csv\")\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>binary_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La experiencia en este hotel fue decepcionante...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Este hotel es un completo desastre. La habitac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pésimo servicio en el hotel, la gente de recep...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>La experiencia en el hotel fue terrible. Desde...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mi experiencia en este hotel fue bastante dece...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>El servicio al cliente fue muy pobre y decepci...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>Mi experiencia en el Fiesta Americana fue muy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>Mi experiencia en este hotel fue completamente...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>La peor experiencia hotelera de mi vida. El pe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>Horrible experiencia en este hotel. La habitac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review  binary_rating\n",
       "0    La experiencia en este hotel fue decepcionante...              0\n",
       "1    Este hotel es un completo desastre. La habitac...              0\n",
       "2    Pésimo servicio en el hotel, la gente de recep...              0\n",
       "3    La experiencia en el hotel fue terrible. Desde...              0\n",
       "4    Mi experiencia en este hotel fue bastante dece...              0\n",
       "..                                                 ...            ...\n",
       "595  El servicio al cliente fue muy pobre y decepci...              0\n",
       "596  Mi experiencia en el Fiesta Americana fue muy ...              0\n",
       "597  Mi experiencia en este hotel fue completamente...              0\n",
       "598  La peor experiencia hotelera de mi vida. El pe...              0\n",
       "599  Horrible experiencia en este hotel. La habitac...              0\n",
       "\n",
       "[600 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['binary_rating'] = 0\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['rating','title'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>binary_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Si buscas un hotel en el Centro de Monterrey H...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Muy buen servicio y atención del todo el perso...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Excelente servicio y atención personal. Muy bu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>El mes pasado mi prima tuvo su getting y me en...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Excelente servicio y atención al cliente.Sobre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754</th>\n",
       "      <td>El servicio al cliente fue muy pobre y decepci...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>Mi experiencia en el Fiesta Americana fue muy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>Mi experiencia en este hotel fue completamente...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>La peor experiencia hotelera de mi vida. El pe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>Horrible experiencia en este hotel. La habitac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1759 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  binary_rating\n",
       "0     Si buscas un hotel en el Centro de Monterrey H...              1\n",
       "1     Muy buen servicio y atención del todo el perso...              1\n",
       "2     Excelente servicio y atención personal. Muy bu...              1\n",
       "3     El mes pasado mi prima tuvo su getting y me en...              1\n",
       "4     Excelente servicio y atención al cliente.Sobre...              1\n",
       "...                                                 ...            ...\n",
       "1754  El servicio al cliente fue muy pobre y decepci...              0\n",
       "1755  Mi experiencia en el Fiesta Americana fue muy ...              0\n",
       "1756  Mi experiencia en este hotel fue completamente...              0\n",
       "1757  La peor experiencia hotelera de mi vida. El pe...              0\n",
       "1758  Horrible experiencia en este hotel. La habitac...              0\n",
       "\n",
       "[1759 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.concat([df, new_df], ignore_index=True)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative comments percentage:  0.503126776577601\n"
     ]
    }
   ],
   "source": [
    "neg_comments_per = final_df['binary_rating'].value_counts()[0] / final_df['binary_rating'].value_counts().sum()\n",
    "print(\"Negative comments percentage: \", neg_comments_per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0337f17ff8284f56b258182165df8a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def compute_metrics(p):\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred)\n",
    "    precision = precision_score(y_true=labels, y_pred=pred)\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred)\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"recall\": recall, \"precision\": precision, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"final_reviews.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos obtenidos se encontraban desbalanceados; contando con ~25% comentarios negativos y ~75% comentarios positivos. Por lo tanto, se optó por utilizar un modelo (LLM) para generar comentarios \"sintéticos\" negativos para balancear el porcentaje ambos tipos de comentarios.\n",
    "\n",
    "Se consideró que los datos sintéticos generados son similares a los datos reales, por lo que esto podría ayudar al modelo a aprender de manera efectiva; esto se valida más adelante durante las etapas de entrenamiento (fine-tuning) del modelo. Asimismo, se toma en consideración que si los datos sintéticos no fuesen representativos, podrían haber llevado al modelo a aprender patrones incorrectos; afectando, así, el rendimiento del modelo. De esta manera, es importante monitorizar los resultados con, y sin, los datos sintéticos durante las etapas de entrenamiento y validación."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Partición de datos originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['review'].copy(), df['binary_rating'].copy(), test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Fine-tuning de Modelo de clasificación binaria en español (datos originales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding, AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"finiteautomata/beto-sentiment-analysis\", num_labels=3).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"finiteautomata/beto-sentiment-analysis\")\n",
    "\n",
    "# if tokenizer.pad_token is None:\n",
    "#     tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "# # Configura '[PAD]' como el token oficial de padding\n",
    "# tokenizer.pad_token = '[PAD]'\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ReviewsDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Tokenización\n",
    "train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
    "val_encodings = tokenizer(X_val.tolist(), truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
    "\n",
    "# Conversión a conjuntos de datos de HuggingFace\n",
    "train_dataset = ReviewsDataset(train_encodings, y_train.tolist())\n",
    "val_dataset = ReviewsDataset(val_encodings, y_val.tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De los mejores lugares, con el mejor servicio. Lugar cercano al centro de la ciudad, muchos lugares que visitar, puedes apoyarte en la gente del Hotel para recomendarte lugares. Cuenta con excelente restaurante, gimnasio y alberca.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POS', 'score': 0.9961075186729431}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sentiment(pipeline, text, max_length=512):\n",
    "    if len(text) > max_length:\n",
    "      text = text[:max_length]\n",
    "    return pipeline.predict(text)\n",
    "sentiment_pipeline = pipeline('sentiment-analysis', tokenizer=tokenizer, model=model.cpu())\n",
    "print(X_test.tolist()[0])\n",
    "prediction = get_sentiment(sentiment_pipeline, X_test.tolist()[0])\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232/232 [00:21<00:00, 10.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of default model: 0.8663793103448276\n",
      "Precision of default model: 0.8967991169977924\n",
      "Recall of default model: 0.8663793103448276\n",
      "F1 Score of default model: 0.8727061427780852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions_default_model = [get_sentiment(sentiment_pipeline, review) for review in tqdm(X_test)]\n",
    "\n",
    "# Convert the predictions to 1 or 0 sentiments\n",
    "predictions_default_model = [1 if prediction[0]['label'] == 'POS' else 0 for prediction in predictions_default_model]\n",
    "\n",
    "# Metrics\n",
    "test_accuracy = accuracy_score(y_test, predictions_default_model)\n",
    "test_precision = precision_score(y_test, predictions_default_model, average='weighted')\n",
    "test_recall = recall_score(y_test, predictions_default_model, average='weighted')\n",
    "test_f1_score = f1_score(y_test, predictions_default_model, average='weighted')\n",
    "\n",
    "print(f'Accuracy of default model: {test_accuracy}')\n",
    "print(f'Precision of default model: {test_precision}')\n",
    "print(f'Recall of default model: {test_recall}')\n",
    "print(f'F1 Score of default model: {test_f1_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "   output_dir=\"./results\",\n",
    "   learning_rate=2e-5,\n",
    "   per_device_train_batch_size=4,\n",
    "   per_device_eval_batch_size=4,\n",
    "   num_train_epochs=10,\n",
    "   weight_decay=0.01,\n",
    "   save_strategy=\"steps\",\n",
    "   evaluation_strategy=\"steps\",\n",
    "   eval_steps=500,\n",
    "   load_best_model_at_end=True,\n",
    "   logging_dir='./logs',            # Directorio de los logs\n",
    "   logging_steps=10,\n",
    "  #  push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "   model=model,\n",
    "   args=training_args,\n",
    "   train_dataset=train_dataset,\n",
    "   eval_dataset=val_dataset,\n",
    "   tokenizer=tokenizer,\n",
    "   data_collator=data_collator,\n",
    "   compute_metrics=compute_metrics,\n",
    "   callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\m1000\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026f6697da48427f96da67696224d5fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/930 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m1000\\AppData\\Local\\Temp\\ipykernel_43156\\221027803.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "c:\\Users\\m1000\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "c:\\Users\\m1000\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2264, 'learning_rate': 1.978494623655914e-05, 'epoch': 0.11}\n",
      "{'loss': 0.6074, 'learning_rate': 1.956989247311828e-05, 'epoch': 0.22}\n",
      "{'loss': 0.3976, 'learning_rate': 1.935483870967742e-05, 'epoch': 0.32}\n",
      "{'loss': 0.3278, 'learning_rate': 1.913978494623656e-05, 'epoch': 0.43}\n",
      "{'loss': 0.4197, 'learning_rate': 1.89247311827957e-05, 'epoch': 0.54}\n",
      "{'loss': 0.0998, 'learning_rate': 1.870967741935484e-05, 'epoch': 0.65}\n",
      "{'loss': 0.4815, 'learning_rate': 1.849462365591398e-05, 'epoch': 0.75}\n",
      "{'loss': 0.3788, 'learning_rate': 1.827956989247312e-05, 'epoch': 0.86}\n",
      "{'loss': 0.3402, 'learning_rate': 1.806451612903226e-05, 'epoch': 0.97}\n",
      "{'loss': 0.0729, 'learning_rate': 1.78494623655914e-05, 'epoch': 1.08}\n",
      "{'loss': 0.1035, 'learning_rate': 1.763440860215054e-05, 'epoch': 1.18}\n",
      "{'loss': 0.0396, 'learning_rate': 1.741935483870968e-05, 'epoch': 1.29}\n",
      "{'loss': 0.2807, 'learning_rate': 1.7204301075268818e-05, 'epoch': 1.4}\n",
      "{'loss': 0.3315, 'learning_rate': 1.6989247311827958e-05, 'epoch': 1.51}\n",
      "{'loss': 0.1144, 'learning_rate': 1.6774193548387098e-05, 'epoch': 1.61}\n",
      "{'loss': 0.1417, 'learning_rate': 1.6559139784946237e-05, 'epoch': 1.72}\n",
      "{'loss': 0.0861, 'learning_rate': 1.6344086021505377e-05, 'epoch': 1.83}\n",
      "{'loss': 0.1507, 'learning_rate': 1.6129032258064517e-05, 'epoch': 1.94}\n",
      "{'loss': 0.0564, 'learning_rate': 1.5913978494623657e-05, 'epoch': 2.04}\n",
      "{'loss': 0.0104, 'learning_rate': 1.5698924731182796e-05, 'epoch': 2.15}\n",
      "{'loss': 0.0012, 'learning_rate': 1.5483870967741936e-05, 'epoch': 2.26}\n",
      "{'loss': 0.0162, 'learning_rate': 1.5268817204301076e-05, 'epoch': 2.37}\n",
      "{'loss': 0.0503, 'learning_rate': 1.5053763440860215e-05, 'epoch': 2.47}\n",
      "{'loss': 0.1046, 'learning_rate': 1.4838709677419357e-05, 'epoch': 2.58}\n",
      "{'loss': 0.0177, 'learning_rate': 1.4623655913978497e-05, 'epoch': 2.69}\n",
      "{'loss': 0.0794, 'learning_rate': 1.4408602150537636e-05, 'epoch': 2.8}\n",
      "{'loss': 0.0007, 'learning_rate': 1.4193548387096776e-05, 'epoch': 2.9}\n",
      "{'loss': 0.0916, 'learning_rate': 1.3978494623655916e-05, 'epoch': 3.01}\n",
      "{'loss': 0.0915, 'learning_rate': 1.3763440860215056e-05, 'epoch': 3.12}\n",
      "{'loss': 0.0014, 'learning_rate': 1.3548387096774194e-05, 'epoch': 3.23}\n",
      "{'loss': 0.0009, 'learning_rate': 1.3333333333333333e-05, 'epoch': 3.33}\n",
      "{'loss': 0.0008, 'learning_rate': 1.3118279569892473e-05, 'epoch': 3.44}\n",
      "{'loss': 0.0006, 'learning_rate': 1.2903225806451613e-05, 'epoch': 3.55}\n",
      "{'loss': 0.0005, 'learning_rate': 1.2688172043010754e-05, 'epoch': 3.66}\n",
      "{'loss': 0.0015, 'learning_rate': 1.2473118279569894e-05, 'epoch': 3.76}\n",
      "{'loss': 0.0005, 'learning_rate': 1.2258064516129034e-05, 'epoch': 3.87}\n",
      "{'loss': 0.0005, 'learning_rate': 1.2043010752688173e-05, 'epoch': 3.98}\n",
      "{'loss': 0.0004, 'learning_rate': 1.1827956989247313e-05, 'epoch': 4.09}\n",
      "{'loss': 0.0003, 'learning_rate': 1.1612903225806453e-05, 'epoch': 4.19}\n",
      "{'loss': 0.0004, 'learning_rate': 1.1397849462365593e-05, 'epoch': 4.3}\n",
      "{'loss': 0.0004, 'learning_rate': 1.118279569892473e-05, 'epoch': 4.41}\n",
      "{'loss': 0.0003, 'learning_rate': 1.096774193548387e-05, 'epoch': 4.52}\n",
      "{'loss': 0.0003, 'learning_rate': 1.0752688172043012e-05, 'epoch': 4.62}\n",
      "{'loss': 0.0802, 'learning_rate': 1.0537634408602151e-05, 'epoch': 4.73}\n",
      "{'loss': 0.0004, 'learning_rate': 1.0322580645161291e-05, 'epoch': 4.84}\n",
      "{'loss': 0.0004, 'learning_rate': 1.0107526881720431e-05, 'epoch': 4.95}\n",
      "{'loss': 0.0004, 'learning_rate': 9.89247311827957e-06, 'epoch': 5.05}\n",
      "{'loss': 0.0003, 'learning_rate': 9.67741935483871e-06, 'epoch': 5.16}\n",
      "{'loss': 0.0003, 'learning_rate': 9.46236559139785e-06, 'epoch': 5.27}\n",
      "{'loss': 0.0003, 'learning_rate': 9.24731182795699e-06, 'epoch': 5.38}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48592dd3990a41a488534d2b6c5ff607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.628998875617981, 'eval_accuracy': 0.8978494623655914, 'eval_recall': 0.9444444444444444, 'eval_precision': 0.9251700680272109, 'eval_f1': 0.9347079037800687, 'eval_runtime': 2.6424, 'eval_samples_per_second': 70.39, 'eval_steps_per_second': 9.083, 'epoch': 5.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m1000\\AppData\\Local\\Temp\\ipykernel_43156\\221027803.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "c:\\Users\\m1000\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "c:\\Users\\m1000\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0003, 'learning_rate': 9.03225806451613e-06, 'epoch': 5.48}\n",
      "{'loss': 0.0002, 'learning_rate': 8.81720430107527e-06, 'epoch': 5.59}\n",
      "{'loss': 0.0002, 'learning_rate': 8.602150537634409e-06, 'epoch': 5.7}\n",
      "{'loss': 0.0008, 'learning_rate': 8.387096774193549e-06, 'epoch': 5.81}\n",
      "{'loss': 0.0002, 'learning_rate': 8.172043010752689e-06, 'epoch': 5.91}\n",
      "{'loss': 0.0003, 'learning_rate': 7.956989247311828e-06, 'epoch': 6.02}\n",
      "{'loss': 0.0003, 'learning_rate': 7.741935483870968e-06, 'epoch': 6.13}\n",
      "{'loss': 0.0023, 'learning_rate': 7.526881720430108e-06, 'epoch': 6.24}\n",
      "{'loss': 0.0002, 'learning_rate': 7.311827956989248e-06, 'epoch': 6.34}\n",
      "{'loss': 0.0002, 'learning_rate': 7.096774193548388e-06, 'epoch': 6.45}\n",
      "{'loss': 0.0002, 'learning_rate': 6.881720430107528e-06, 'epoch': 6.56}\n",
      "{'loss': 0.0002, 'learning_rate': 6.666666666666667e-06, 'epoch': 6.67}\n",
      "{'loss': 0.0002, 'learning_rate': 6.451612903225806e-06, 'epoch': 6.77}\n",
      "{'loss': 0.0002, 'learning_rate': 6.236559139784947e-06, 'epoch': 6.88}\n",
      "{'loss': 0.0002, 'learning_rate': 6.021505376344087e-06, 'epoch': 6.99}\n",
      "{'loss': 0.0002, 'learning_rate': 5.806451612903226e-06, 'epoch': 7.1}\n",
      "{'loss': 0.0002, 'learning_rate': 5.591397849462365e-06, 'epoch': 7.2}\n",
      "{'loss': 0.0002, 'learning_rate': 5.376344086021506e-06, 'epoch': 7.31}\n",
      "{'loss': 0.0002, 'learning_rate': 5.161290322580646e-06, 'epoch': 7.42}\n",
      "{'loss': 0.0002, 'learning_rate': 4.946236559139785e-06, 'epoch': 7.53}\n",
      "{'loss': 0.0002, 'learning_rate': 4.731182795698925e-06, 'epoch': 7.63}\n",
      "{'loss': 0.0002, 'learning_rate': 4.516129032258065e-06, 'epoch': 7.74}\n",
      "{'loss': 0.0002, 'learning_rate': 4.3010752688172045e-06, 'epoch': 7.85}\n",
      "{'loss': 0.0002, 'learning_rate': 4.086021505376344e-06, 'epoch': 7.96}\n",
      "{'loss': 0.0001, 'learning_rate': 3.870967741935484e-06, 'epoch': 8.06}\n",
      "{'loss': 0.0002, 'learning_rate': 3.655913978494624e-06, 'epoch': 8.17}\n",
      "{'loss': 0.0002, 'learning_rate': 3.440860215053764e-06, 'epoch': 8.28}\n",
      "{'loss': 0.0002, 'learning_rate': 3.225806451612903e-06, 'epoch': 8.39}\n",
      "{'loss': 0.0001, 'learning_rate': 3.0107526881720433e-06, 'epoch': 8.49}\n",
      "{'loss': 0.0002, 'learning_rate': 2.7956989247311827e-06, 'epoch': 8.6}\n",
      "{'loss': 0.0001, 'learning_rate': 2.580645161290323e-06, 'epoch': 8.71}\n",
      "{'loss': 0.0002, 'learning_rate': 2.3655913978494625e-06, 'epoch': 8.82}\n",
      "{'loss': 0.0001, 'learning_rate': 2.1505376344086023e-06, 'epoch': 8.92}\n",
      "{'loss': 0.0001, 'learning_rate': 1.935483870967742e-06, 'epoch': 9.03}\n",
      "{'loss': 0.0001, 'learning_rate': 1.720430107526882e-06, 'epoch': 9.14}\n",
      "{'loss': 0.0001, 'learning_rate': 1.5053763440860217e-06, 'epoch': 9.25}\n",
      "{'loss': 0.0002, 'learning_rate': 1.2903225806451614e-06, 'epoch': 9.35}\n",
      "{'loss': 0.0001, 'learning_rate': 1.0752688172043011e-06, 'epoch': 9.46}\n",
      "{'loss': 0.0001, 'learning_rate': 8.60215053763441e-07, 'epoch': 9.57}\n",
      "{'loss': 0.0002, 'learning_rate': 6.451612903225807e-07, 'epoch': 9.68}\n",
      "{'loss': 0.0001, 'learning_rate': 4.301075268817205e-07, 'epoch': 9.78}\n",
      "{'loss': 0.0002, 'learning_rate': 2.1505376344086024e-07, 'epoch': 9.89}\n",
      "{'loss': 0.0001, 'learning_rate': 0.0, 'epoch': 10.0}\n",
      "{'train_runtime': 372.2627, 'train_samples_per_second': 19.905, 'train_steps_per_second': 2.498, 'train_loss': 0.06690130372511684, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=930, training_loss=0.06690130372511684, metrics={'train_runtime': 372.2627, 'train_samples_per_second': 19.905, 'train_steps_per_second': 2.498, 'train_loss': 0.06690130372511684, 'epoch': 10.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m1000\\AppData\\Local\\Temp\\ipykernel_43156\\221027803.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1971ead264a14fb0ad712a27cece9491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.628998875617981,\n",
       " 'eval_accuracy': 0.8978494623655914,\n",
       " 'eval_recall': 0.9444444444444444,\n",
       " 'eval_precision': 0.9251700680272109,\n",
       " 'eval_f1': 0.9347079037800687,\n",
       " 'eval_runtime': 3.713,\n",
       " 'eval_samples_per_second': 50.094,\n",
       " 'eval_steps_per_second': 6.464,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se muestran los resultados obtenidos con el modelo por defecto, así como el modelo ajustado con los datos originales (sin datos sintéticos):\n",
    "\n",
    "| Metric | Default Model | Fine-tuned Model |\n",
    "|---|---|---|\n",
    "| Accuracy  | 0.8664  | 0.8978  |\n",
    "| Precision | 0.8968  | 0.9252  |\n",
    "| Recall    | 0.8664  | 0.9444  |\n",
    "| F1 Score  | 0.8727  | 0.9347  |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Fine-tuning de Modelo de clasificación binaria en español (con datos sintéticos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>binary_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Si buscas un hotel en el Centro de Monterrey H...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Muy buen servicio y atención del todo el perso...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Excelente servicio y atención personal. Muy bu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>El mes pasado mi prima tuvo su getting y me en...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Excelente servicio y atención al cliente.Sobre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754</th>\n",
       "      <td>El servicio al cliente fue muy pobre y decepci...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>Mi experiencia en el Fiesta Americana fue muy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>Mi experiencia en este hotel fue completamente...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>La peor experiencia hotelera de mi vida. El pe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>Horrible experiencia en este hotel. La habitac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1759 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  binary_rating\n",
       "0     Si buscas un hotel en el Centro de Monterrey H...              1\n",
       "1     Muy buen servicio y atención del todo el perso...              1\n",
       "2     Excelente servicio y atención personal. Muy bu...              1\n",
       "3     El mes pasado mi prima tuvo su getting y me en...              1\n",
       "4     Excelente servicio y atención al cliente.Sobre...              1\n",
       "...                                                 ...            ...\n",
       "1754  El servicio al cliente fue muy pobre y decepci...              0\n",
       "1755  Mi experiencia en el Fiesta Americana fue muy ...              0\n",
       "1756  Mi experiencia en este hotel fue completamente...              0\n",
       "1757  La peor experiencia hotelera de mi vida. El pe...              0\n",
       "1758  Horrible experiencia en este hotel. La habitac...              0\n",
       "\n",
       "[1759 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.read_csv(\"final_reviews.csv\")\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(final_df['review'].copy(), final_df['binary_rating'].copy(), test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenización\n",
    "train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
    "val_encodings = tokenizer(X_val.tolist(), truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
    "\n",
    "# Conversión a conjuntos de datos de HuggingFace\n",
    "train_dataset = ReviewsDataset(train_encodings, y_train.tolist())\n",
    "val_dataset = ReviewsDataset(val_encodings, y_val.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "   output_dir=\"./results\",\n",
    "   learning_rate=2e-5,\n",
    "   per_device_train_batch_size=4,\n",
    "   per_device_eval_batch_size=4,\n",
    "   num_train_epochs=10,\n",
    "   weight_decay=0.01,\n",
    "   save_strategy=\"steps\",\n",
    "   evaluation_strategy=\"steps\",\n",
    "   eval_steps=500,\n",
    "   load_best_model_at_end=True,\n",
    "   logging_dir='./logs',            \n",
    "   logging_steps=10,\n",
    "  #  push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "   model=model,\n",
    "   args=training_args,\n",
    "   train_dataset=train_dataset,\n",
    "   eval_dataset=val_dataset,\n",
    "   tokenizer=tokenizer,\n",
    "   data_collator=data_collator,\n",
    "   compute_metrics=compute_metrics,\n",
    "   callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\m1000\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0110e04a57d542fb9d47ad718549f456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1410 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m1000\\AppData\\Local\\Temp\\ipykernel_43156\\221027803.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "c:\\Users\\m1000\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "c:\\Users\\m1000\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2086, 'learning_rate': 1.9858156028368796e-05, 'epoch': 0.07}\n",
      "{'loss': 0.2305, 'learning_rate': 1.971631205673759e-05, 'epoch': 0.14}\n",
      "{'loss': 0.0803, 'learning_rate': 1.9574468085106384e-05, 'epoch': 0.21}\n",
      "{'loss': 0.2565, 'learning_rate': 1.9432624113475178e-05, 'epoch': 0.28}\n",
      "{'loss': 0.0568, 'learning_rate': 1.929078014184397e-05, 'epoch': 0.35}\n",
      "{'loss': 0.135, 'learning_rate': 1.914893617021277e-05, 'epoch': 0.43}\n",
      "{'loss': 0.1339, 'learning_rate': 1.9007092198581563e-05, 'epoch': 0.5}\n",
      "{'loss': 0.0045, 'learning_rate': 1.8865248226950357e-05, 'epoch': 0.57}\n",
      "{'loss': 0.0861, 'learning_rate': 1.872340425531915e-05, 'epoch': 0.64}\n",
      "{'loss': 0.2625, 'learning_rate': 1.8581560283687945e-05, 'epoch': 0.71}\n",
      "{'loss': 0.1516, 'learning_rate': 1.843971631205674e-05, 'epoch': 0.78}\n",
      "{'loss': 0.0047, 'learning_rate': 1.8297872340425533e-05, 'epoch': 0.85}\n",
      "{'loss': 0.0285, 'learning_rate': 1.8156028368794327e-05, 'epoch': 0.92}\n",
      "{'loss': 0.0155, 'learning_rate': 1.801418439716312e-05, 'epoch': 0.99}\n",
      "{'loss': 0.0049, 'learning_rate': 1.7872340425531915e-05, 'epoch': 1.06}\n",
      "{'loss': 0.0015, 'learning_rate': 1.773049645390071e-05, 'epoch': 1.13}\n",
      "{'loss': 0.0875, 'learning_rate': 1.7588652482269506e-05, 'epoch': 1.21}\n",
      "{'loss': 0.0516, 'learning_rate': 1.74468085106383e-05, 'epoch': 1.28}\n",
      "{'loss': 0.0779, 'learning_rate': 1.7304964539007094e-05, 'epoch': 1.35}\n",
      "{'loss': 0.0561, 'learning_rate': 1.716312056737589e-05, 'epoch': 1.42}\n",
      "{'loss': 0.0025, 'learning_rate': 1.7021276595744682e-05, 'epoch': 1.49}\n",
      "{'loss': 0.0008, 'learning_rate': 1.6879432624113476e-05, 'epoch': 1.56}\n",
      "{'loss': 0.0014, 'learning_rate': 1.673758865248227e-05, 'epoch': 1.63}\n",
      "{'loss': 0.0004, 'learning_rate': 1.6595744680851064e-05, 'epoch': 1.7}\n",
      "{'loss': 0.0004, 'learning_rate': 1.645390070921986e-05, 'epoch': 1.77}\n",
      "{'loss': 0.0899, 'learning_rate': 1.6312056737588652e-05, 'epoch': 1.84}\n",
      "{'loss': 0.0025, 'learning_rate': 1.6170212765957446e-05, 'epoch': 1.91}\n",
      "{'loss': 0.0873, 'learning_rate': 1.6028368794326244e-05, 'epoch': 1.99}\n",
      "{'loss': 0.0922, 'learning_rate': 1.5886524822695038e-05, 'epoch': 2.06}\n",
      "{'loss': 0.0014, 'learning_rate': 1.5744680851063832e-05, 'epoch': 2.13}\n",
      "{'loss': 0.0013, 'learning_rate': 1.5602836879432626e-05, 'epoch': 2.2}\n",
      "{'loss': 0.0448, 'learning_rate': 1.546099290780142e-05, 'epoch': 2.27}\n",
      "{'loss': 0.0002, 'learning_rate': 1.5319148936170214e-05, 'epoch': 2.34}\n",
      "{'loss': 0.0004, 'learning_rate': 1.5177304964539008e-05, 'epoch': 2.41}\n",
      "{'loss': 0.0003, 'learning_rate': 1.5035460992907802e-05, 'epoch': 2.48}\n",
      "{'loss': 0.0003, 'learning_rate': 1.4893617021276596e-05, 'epoch': 2.55}\n",
      "{'loss': 0.0002, 'learning_rate': 1.475177304964539e-05, 'epoch': 2.62}\n",
      "{'loss': 0.0002, 'learning_rate': 1.4609929078014187e-05, 'epoch': 2.7}\n",
      "{'loss': 0.0002, 'learning_rate': 1.4468085106382981e-05, 'epoch': 2.77}\n",
      "{'loss': 0.0425, 'learning_rate': 1.4326241134751775e-05, 'epoch': 2.84}\n",
      "{'loss': 0.0002, 'learning_rate': 1.418439716312057e-05, 'epoch': 2.91}\n",
      "{'loss': 0.0003, 'learning_rate': 1.4042553191489363e-05, 'epoch': 2.98}\n",
      "{'loss': 0.0002, 'learning_rate': 1.3900709219858157e-05, 'epoch': 3.05}\n",
      "{'loss': 0.0002, 'learning_rate': 1.3758865248226951e-05, 'epoch': 3.12}\n",
      "{'loss': 0.0002, 'learning_rate': 1.3617021276595745e-05, 'epoch': 3.19}\n",
      "{'loss': 0.0003, 'learning_rate': 1.347517730496454e-05, 'epoch': 3.26}\n",
      "{'loss': 0.0001, 'learning_rate': 1.3333333333333333e-05, 'epoch': 3.33}\n",
      "{'loss': 0.0001, 'learning_rate': 1.3191489361702127e-05, 'epoch': 3.4}\n",
      "{'loss': 0.0001, 'learning_rate': 1.3049645390070925e-05, 'epoch': 3.48}\n",
      "{'loss': 0.0001, 'learning_rate': 1.2907801418439719e-05, 'epoch': 3.55}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d68594427194b51afae8f99fa7fe260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09445394575595856, 'eval_accuracy': 0.9893617021276596, 'eval_recall': 0.9919354838709677, 'eval_precision': 0.984, 'eval_f1': 0.9879518072289156, 'eval_runtime': 4.1618, 'eval_samples_per_second': 67.759, 'eval_steps_per_second': 8.65, 'epoch': 3.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m1000\\AppData\\Local\\Temp\\ipykernel_43156\\221027803.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "c:\\Users\\m1000\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "c:\\Users\\m1000\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0001, 'learning_rate': 1.2765957446808513e-05, 'epoch': 3.62}\n",
      "{'loss': 0.0001, 'learning_rate': 1.2624113475177307e-05, 'epoch': 3.69}\n",
      "{'loss': 0.0001, 'learning_rate': 1.24822695035461e-05, 'epoch': 3.76}\n",
      "{'loss': 0.0001, 'learning_rate': 1.2340425531914895e-05, 'epoch': 3.83}\n",
      "{'loss': 0.0001, 'learning_rate': 1.2198581560283689e-05, 'epoch': 3.9}\n",
      "{'loss': 0.0001, 'learning_rate': 1.2056737588652483e-05, 'epoch': 3.97}\n",
      "{'loss': 0.0001, 'learning_rate': 1.1914893617021277e-05, 'epoch': 4.04}\n",
      "{'loss': 0.008, 'learning_rate': 1.177304964539007e-05, 'epoch': 4.11}\n",
      "{'loss': 0.0001, 'learning_rate': 1.1631205673758865e-05, 'epoch': 4.18}\n",
      "{'loss': 0.0001, 'learning_rate': 1.1489361702127662e-05, 'epoch': 4.26}\n",
      "{'loss': 0.0001, 'learning_rate': 1.1347517730496456e-05, 'epoch': 4.33}\n",
      "{'loss': 0.0001, 'learning_rate': 1.120567375886525e-05, 'epoch': 4.4}\n",
      "{'loss': 0.0001, 'learning_rate': 1.1063829787234044e-05, 'epoch': 4.47}\n",
      "{'loss': 0.0001, 'learning_rate': 1.0921985815602838e-05, 'epoch': 4.54}\n",
      "{'loss': 0.0001, 'learning_rate': 1.0780141843971632e-05, 'epoch': 4.61}\n",
      "{'loss': 0.0001, 'learning_rate': 1.0638297872340426e-05, 'epoch': 4.68}\n",
      "{'loss': 0.0001, 'learning_rate': 1.049645390070922e-05, 'epoch': 4.75}\n",
      "{'loss': 0.0001, 'learning_rate': 1.0354609929078014e-05, 'epoch': 4.82}\n",
      "{'loss': 0.0001, 'learning_rate': 1.0212765957446808e-05, 'epoch': 4.89}\n",
      "{'loss': 0.0001, 'learning_rate': 1.0070921985815602e-05, 'epoch': 4.96}\n",
      "{'loss': 0.0001, 'learning_rate': 9.929078014184398e-06, 'epoch': 5.04}\n",
      "{'loss': 0.0001, 'learning_rate': 9.787234042553192e-06, 'epoch': 5.11}\n",
      "{'loss': 0.0001, 'learning_rate': 9.645390070921986e-06, 'epoch': 5.18}\n",
      "{'loss': 0.0001, 'learning_rate': 9.503546099290782e-06, 'epoch': 5.25}\n",
      "{'loss': 0.0001, 'learning_rate': 9.361702127659576e-06, 'epoch': 5.32}\n",
      "{'loss': 0.0001, 'learning_rate': 9.21985815602837e-06, 'epoch': 5.39}\n",
      "{'loss': 0.0001, 'learning_rate': 9.078014184397164e-06, 'epoch': 5.46}\n",
      "{'loss': 0.0001, 'learning_rate': 8.936170212765958e-06, 'epoch': 5.53}\n",
      "{'loss': 0.0001, 'learning_rate': 8.794326241134753e-06, 'epoch': 5.6}\n",
      "{'loss': 0.0001, 'learning_rate': 8.652482269503547e-06, 'epoch': 5.67}\n",
      "{'loss': 0.0001, 'learning_rate': 8.510638297872341e-06, 'epoch': 5.74}\n",
      "{'loss': 0.0001, 'learning_rate': 8.368794326241135e-06, 'epoch': 5.82}\n",
      "{'loss': 0.0001, 'learning_rate': 8.22695035460993e-06, 'epoch': 5.89}\n",
      "{'loss': 0.0001, 'learning_rate': 8.085106382978723e-06, 'epoch': 5.96}\n",
      "{'loss': 0.0001, 'learning_rate': 7.943262411347519e-06, 'epoch': 6.03}\n",
      "{'loss': 0.0001, 'learning_rate': 7.801418439716313e-06, 'epoch': 6.1}\n",
      "{'loss': 0.0001, 'learning_rate': 7.659574468085107e-06, 'epoch': 6.17}\n",
      "{'loss': 0.0001, 'learning_rate': 7.517730496453901e-06, 'epoch': 6.24}\n",
      "{'loss': 0.0001, 'learning_rate': 7.375886524822695e-06, 'epoch': 6.31}\n",
      "{'loss': 0.0001, 'learning_rate': 7.234042553191491e-06, 'epoch': 6.38}\n",
      "{'loss': 0.0001, 'learning_rate': 7.092198581560285e-06, 'epoch': 6.45}\n",
      "{'loss': 0.0001, 'learning_rate': 6.950354609929079e-06, 'epoch': 6.52}\n",
      "{'loss': 0.0001, 'learning_rate': 6.808510638297873e-06, 'epoch': 6.6}\n",
      "{'loss': 0.0001, 'learning_rate': 6.666666666666667e-06, 'epoch': 6.67}\n",
      "{'loss': 0.0001, 'learning_rate': 6.524822695035462e-06, 'epoch': 6.74}\n",
      "{'loss': 0.0001, 'learning_rate': 6.382978723404256e-06, 'epoch': 6.81}\n",
      "{'loss': 0.0001, 'learning_rate': 6.24113475177305e-06, 'epoch': 6.88}\n",
      "{'loss': 0.0001, 'learning_rate': 6.099290780141844e-06, 'epoch': 6.95}\n",
      "{'loss': 0.0, 'learning_rate': 5.957446808510638e-06, 'epoch': 7.02}\n",
      "{'loss': 0.0, 'learning_rate': 5.815602836879432e-06, 'epoch': 7.09}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81cac0a64fbe45339ff97d1da9f2be91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12397931516170502, 'eval_accuracy': 0.9858156028368794, 'eval_recall': 0.9838709677419355, 'eval_precision': 0.9838709677419355, 'eval_f1': 0.9838709677419355, 'eval_runtime': 4.2315, 'eval_samples_per_second': 66.643, 'eval_steps_per_second': 8.508, 'epoch': 7.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m1000\\AppData\\Local\\Temp\\ipykernel_43156\\221027803.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "c:\\Users\\m1000\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "c:\\Users\\m1000\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0001, 'learning_rate': 5.673758865248228e-06, 'epoch': 7.16}\n",
      "{'loss': 0.0001, 'learning_rate': 5.531914893617022e-06, 'epoch': 7.23}\n",
      "{'loss': 0.0, 'learning_rate': 5.390070921985816e-06, 'epoch': 7.3}\n",
      "{'loss': 0.0001, 'learning_rate': 5.24822695035461e-06, 'epoch': 7.38}\n",
      "{'loss': 0.0, 'learning_rate': 5.106382978723404e-06, 'epoch': 7.45}\n",
      "{'loss': 0.0, 'learning_rate': 4.964539007092199e-06, 'epoch': 7.52}\n",
      "{'loss': 0.0, 'learning_rate': 4.822695035460993e-06, 'epoch': 7.59}\n",
      "{'loss': 0.0, 'learning_rate': 4.680851063829788e-06, 'epoch': 7.66}\n",
      "{'loss': 0.0, 'learning_rate': 4.539007092198582e-06, 'epoch': 7.73}\n",
      "{'loss': 0.0, 'learning_rate': 4.397163120567377e-06, 'epoch': 7.8}\n",
      "{'loss': 0.0, 'learning_rate': 4.255319148936171e-06, 'epoch': 7.87}\n",
      "{'loss': 0.0, 'learning_rate': 4.113475177304965e-06, 'epoch': 7.94}\n",
      "{'loss': 0.0, 'learning_rate': 3.9716312056737595e-06, 'epoch': 8.01}\n",
      "{'loss': 0.0, 'learning_rate': 3.8297872340425535e-06, 'epoch': 8.09}\n",
      "{'loss': 0.0, 'learning_rate': 3.6879432624113475e-06, 'epoch': 8.16}\n",
      "{'loss': 0.0, 'learning_rate': 3.5460992907801423e-06, 'epoch': 8.23}\n",
      "{'loss': 0.0, 'learning_rate': 3.4042553191489363e-06, 'epoch': 8.3}\n",
      "{'loss': 0.0, 'learning_rate': 3.262411347517731e-06, 'epoch': 8.37}\n",
      "{'loss': 0.0, 'learning_rate': 3.120567375886525e-06, 'epoch': 8.44}\n",
      "{'loss': 0.0, 'learning_rate': 2.978723404255319e-06, 'epoch': 8.51}\n",
      "{'loss': 0.0, 'learning_rate': 2.836879432624114e-06, 'epoch': 8.58}\n",
      "{'loss': 0.0, 'learning_rate': 2.695035460992908e-06, 'epoch': 8.65}\n",
      "{'loss': 0.0, 'learning_rate': 2.553191489361702e-06, 'epoch': 8.72}\n",
      "{'loss': 0.0, 'learning_rate': 2.4113475177304965e-06, 'epoch': 8.79}\n",
      "{'loss': 0.0, 'learning_rate': 2.269503546099291e-06, 'epoch': 8.87}\n",
      "{'loss': 0.0, 'learning_rate': 2.1276595744680853e-06, 'epoch': 8.94}\n",
      "{'loss': 0.0, 'learning_rate': 1.9858156028368797e-06, 'epoch': 9.01}\n",
      "{'loss': 0.0, 'learning_rate': 1.8439716312056737e-06, 'epoch': 9.08}\n",
      "{'loss': 0.0, 'learning_rate': 1.7021276595744682e-06, 'epoch': 9.15}\n",
      "{'loss': 0.0, 'learning_rate': 1.5602836879432626e-06, 'epoch': 9.22}\n",
      "{'loss': 0.0, 'learning_rate': 1.418439716312057e-06, 'epoch': 9.29}\n",
      "{'loss': 0.0, 'learning_rate': 1.276595744680851e-06, 'epoch': 9.36}\n",
      "{'loss': 0.0, 'learning_rate': 1.1347517730496454e-06, 'epoch': 9.43}\n",
      "{'loss': 0.0, 'learning_rate': 9.929078014184399e-07, 'epoch': 9.5}\n",
      "{'loss': 0.0, 'learning_rate': 8.510638297872341e-07, 'epoch': 9.57}\n",
      "{'loss': 0.0, 'learning_rate': 7.092198581560285e-07, 'epoch': 9.65}\n",
      "{'loss': 0.0, 'learning_rate': 5.673758865248227e-07, 'epoch': 9.72}\n",
      "{'loss': 0.0, 'learning_rate': 4.2553191489361704e-07, 'epoch': 9.79}\n",
      "{'loss': 0.0, 'learning_rate': 2.8368794326241136e-07, 'epoch': 9.86}\n",
      "{'loss': 0.0, 'learning_rate': 1.4184397163120568e-07, 'epoch': 9.93}\n",
      "{'loss': 0.0, 'learning_rate': 0.0, 'epoch': 10.0}\n",
      "{'train_runtime': 816.9324, 'train_samples_per_second': 13.771, 'train_steps_per_second': 1.726, 'train_loss': 0.016444887505333988, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1410, training_loss=0.016444887505333988, metrics={'train_runtime': 816.9324, 'train_samples_per_second': 13.771, 'train_steps_per_second': 1.726, 'train_loss': 0.016444887505333988, 'epoch': 10.0})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m1000\\AppData\\Local\\Temp\\ipykernel_43156\\221027803.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "846985a43c5141dcbb42a421dd7acc9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.09445394575595856,\n",
       " 'eval_accuracy': 0.9893617021276596,\n",
       " 'eval_recall': 0.9919354838709677,\n",
       " 'eval_precision': 0.984,\n",
       " 'eval_f1': 0.9879518072289156,\n",
       " 'eval_runtime': 4.5855,\n",
       " 'eval_samples_per_second': 61.499,\n",
       " 'eval_steps_per_second': 7.851,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*¿Por qué en este caso no se justificaría utilizar la técnica out-of-box para entrenar y evaluar directamente los datos con los comentarios sintéticos?*\n",
    "\n",
    "No se justificaría utilizar el modelo por defecto para evaluar el dataset con comentarios \"sintéticos\" ya que se busca que el modelo se ajuste a las características específicas del conjunto de datos utilizado; lo cual se logra con la técnica de \"fine-tuning\".\n",
    "\n",
    "A continuación se muestran los resultados obtenidos:\n",
    "\n",
    "| Metric        | Value                 |\n",
    "|---------------|-----------------------|\n",
    "| eval_accuracy | 0.9893617021276596    |\n",
    "| eval_recall   | 0.9919354838709677    |\n",
    "| eval_precision| 0.984                 |\n",
    "| eval_f1       | 0.9879518072289156    |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Comparación de resultados\n",
    "\n",
    "Los resultados obtenidos con datos sintéticos parecen ser significativamente mejores que los obtenidos con los datos originales. En todos los indicadores (precisión, recall, F1 y accuracy), el modelo entrenado con los datos sintéticos superó al modelo entrenado con los datos originales.\n",
    "\n",
    "Este mejor rendimiento puede deberse a que los datos sintéticos ayudaron a balancear el conjunto de datos y a proporcionar más ejemplos para que el modelo aprendiera patrones más diversos. Y esta mejora en la representatividad de los datos podría haber permitido que el modelo generalizara mejor en el conjunto de validación.\n",
    "\n",
    "En este caso, los comentarios sintéticos parecen haber sido útiles para mejorar el rendimiento del modelo. Sin embargo, resulta importante evaluar la calidad de los datos sintéticos y cómo afectan el rendimiento del modelo en cuestión, ya que pueden introducir ruido o desviaciones si no se generan correctamente.\n",
    "\n",
    "\n",
    "\n",
    "| Metric       | Default Model | Fine-tuned Model with Original Data | Fine-tuned Model with Synthetic Data |\n",
    "|--------------|-------------- |------------|-------------------------------------|\n",
    "| Accuracy     | 0.8664        | 0.8978     | 0.9894                              |\n",
    "| Precision    | 0.8968        | 0.9252     | 0.984                               |\n",
    "| Recall       | 0.8664        | 0.9444     | 0.9919                              |\n",
    "| F1 Score     | 0.8727        | 0.9347     | 0.9879                              | \n",
    "\n",
    "Esta tabla proporciona una vista directa de cómo cada modelo se compara en cada métrica. El modelo ajustado con datos sintéticos supera a los otros dos en todas las métricas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
